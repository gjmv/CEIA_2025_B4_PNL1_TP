{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests \n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizo como dataset el epub de Drácula"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funcion auxiliar para descargar el dataset\n",
        "def download_dataset(dataset_url: str, target_filename: str, force: bool = False):\n",
        "    if os.path.exists(target_filename) and not force:\n",
        "        print(\"Dataset folder already exists, nothing downloaded.\")\n",
        "        return\n",
        "\n",
        "    os.makedirs(os.path.dirname(target_filename), exist_ok=True)\n",
        "    try:\n",
        "        with requests.get(dataset_url, stream=True) as response:\n",
        "            response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "            with open(target_filename, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "        print(f\"File '{target_filename}' downloaded successfully.\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        raise(Exception(f\"Error downloading file: {e}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset folder already exists, nothing downloaded.\n"
          ]
        }
      ],
      "source": [
        "# Descargar el dataset\n",
        "dataset = \"datasets/dracula.txt\"\n",
        "download_dataset(\"https://www.gutenberg.org/cache/epub/345/pg345.txt\", dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6v_ickFwBJTy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of article text: 860387 characters\n"
          ]
        }
      ],
      "source": [
        "# Leo todas las líneas del archivo\n",
        "df = pd.read_csv(dataset, sep='/n', header=None, engine=\"python\")\n",
        "df.head()\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "#  Concateno todas las líneas en un solo string, en minúsculas\n",
        "for _, row in df[:None].iterrows():\n",
        "    article_text += row[0].lower() + ' '\n",
        "\n",
        "print(f\"Length of article text: {len(article_text)} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of article text: 419172 characters\n"
          ]
        }
      ],
      "source": [
        "# Recorto el texto para que sea mas manejable\n",
        "article_text = article_text.split(\"*** START OF THE PROJECT GUTENBERG EBOOK DRACULA ***\".lower())[1]\n",
        "article_text = article_text.split(\"*** END OF THE PROJECT GUTENBERG EBOOK DRACULA ***\".lower())[0]\n",
        "# Quito espacios extras\n",
        "article_text = \" \".join(article_text.split())\n",
        "# Me quedo solo con la mitad del texto\n",
        "article_text = article_text[:len(article_text)//2]\n",
        "print(f\"Length of article text: {len(article_text)} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WBE0sSYuB-E6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'en able to throw them off so easily. before us lay a green sloping land full of forests and woods, with here and there steep hills, crowned with clumps of trees or with farmhouses, the blank gable end to the road. there was everywhere a bewildering mass of fruit blossom--apple, plum, pear, cherry; and as we drove by i could see the green grass under the trees spangled with the fallen petals. in and out amongst these green hills of what they call here the “mittel land” ran the road, losing itself as it swept round the grassy curve, or was shut out by the straggling ends of pine woods, which here and there ran down the hillsides like tongues of flame. the road was rugged, but still we seemed to fly over it with a feverish haste. i could not understand then what the haste meant, but the driver was evidently bent on losing no time in reaching borgo prund. i was told that this road is in summertime excellent, but that it had not yet been put in order after the winter snows. in this respect '"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en article text se encuentra el texto del libro\n",
        "article_text[15000:16000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VwTK6xgLJd8q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PwGVSKOiJ5bj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68, 41, 23, 12, 24, 49, 23, 11, 0, 37, 4, 0, 11, 37, 41, 23, 65, 11, 27, 48, 66, 59, 62, 41, 11, 8, 45, 49, 49, 24, 27, 48, 41, 23, 48, 45, 66, 64, 43, 11, 12, 66, 49, 66, 6, 50, 66, 64, 57, 11, 64, 62, 19, 11, 4, 66, 41, 59, 11, 40, 41, 66, 27, 27, 62, 48, 11, 51, 11, 68, 24, 64, 49, 23, 6, 11, 0, 6, 24, 37, 49, 45, 27, 50, 62, 41, 27, 0, 11, 12, 66, 6, 4, 41, 45, 40, 50, 48, 2, 11, 52, 54, 18, 34, 2, 11, 45, 64, 11, 48, 50, 62, 11, 24, 64, 45, 48, 62, 68, 11, 27, 48, 23, 48, 62, 27, 11, 66, 26, 11, 23, 65, 62, 41, 45, 12, 23, 2, 11, 23, 12, 12, 66, 41, 68, 45, 64, 40, 11, 48, 66, 11, 23, 12, 48, 11, 66, 26, 11, 12, 66, 64, 40, 41, 62, 27, 27, 2, 11, 37, 4, 11, 37, 41, 23, 65, 11, 27, 48, 66, 59, 62, 41, 11, 8, 0, 23, 49, 49, 11, 41, 45, 40, 50, 48, 27, 11, 41, 62, 27, 62, 41, 21, 62, 68, 5, 0, 57, 11, 6, 41, 45, 64, 48, 62, 68, 11, 45, 64, 11, 48, 50, 62, 11, 24, 64, 45, 48, 62, 68, 11, 27, 48, 23, 48, 62, 27, 11, 23, 48, 11, 48, 50, 62, 11, 12, 66, 24, 64, 48, 41, 4, 11, 49, 45, 26, 62, 11, 6, 41, 62, 27, 27, 2, 11, 40, 23, 41, 68, 62, 64, 11, 12, 45, 48, 4, 2, 11, 64, 5, 4, 5, 11, 48, 66, 11, 65, 4, 11, 68, 62, 23, 41, 11, 26, 41, 45, 62, 64, 68, 11, 50, 66, 65, 65, 4, 9, 37, 62, 40, 11, 12, 66, 64, 48, 62, 64, 48, 27, 11, 12, 50, 23, 6, 48, 62, 41, 11, 45, 5, 11, 38, 66, 64, 23, 48, 50, 23, 64, 11, 50, 23, 41, 59, 62, 41, 15, 27, 11, 38, 66, 24, 41, 64, 23, 49, 11, 12, 50, 23, 6, 48, 62, 41, 11, 45, 45, 5, 11, 38, 66, 64, 23, 48, 50, 23, 64, 11, 50, 23, 41, 59, 62, 41, 15, 27, 11, 38, 66, 24, 41, 64, 23, 49, 11, 12, 50, 23, 6, 48, 62, 41, 11, 45, 45, 45, 5, 11, 38, 66, 64, 23, 48, 50, 23, 64, 11, 50, 23, 41, 59, 62, 41, 15, 27, 11, 38, 66, 24, 41, 64, 23, 49, 11, 12, 50, 23, 6, 48, 62, 41, 11, 45, 21, 5, 11, 38, 66, 64, 23, 48, 50, 23, 64, 11, 50, 23, 41, 59, 62, 41, 15, 27, 11, 38, 66, 24, 41, 64, 23, 49, 11, 12, 50, 23, 6, 48, 62, 41, 11, 21, 5, 11, 49, 62, 48, 48, 62, 41, 27, 3, 49, 24, 12, 4, 11, 23, 64, 68, 11, 65, 45, 64, 23, 11, 12, 50, 23, 6, 48, 62, 41, 11, 21, 45, 5, 11, 65, 45, 64, 23, 11, 65, 24, 41, 41, 23, 4, 15, 27, 11, 38, 66, 24, 41, 64, 23, 49, 11, 12, 50, 23, 6, 48, 62, 41, 11, 21, 45, 45, 5, 11, 12, 24, 48, 48, 45, 64, 40, 11, 26, 41, 66, 65, 11, 60, 48, 50, 62, 11, 68, 23, 45, 49, 4, 40, 41, 23, 6, 50, 2, 35, 11, 54, 11, 23, 24, 40, 24, 27, 48, 11, 12, 50, 23, 6, 48, 62, 41, 11, 21, 45, 45, 45, 5, 11, 65, 45, 64, 23, 11, 65, 24, 41, 41, 23, 4, 15, 27, 11, 38, 66, 24, 41, 64, 23, 49, 11, 12, 50, 23, 6, 48, 62, 41, 11, 45, 16, 5, 11, 65, 45, 64, 23, 11, 65, 24, 41, 41, 23, 4, 15, 27, 11, 38, 66, 24, 41, 64, 23, 49, 11, 12, 50, 23, 6, 48, 62, 41, 11, 16, 5, 11, 65, 45, 64, 23, 11, 65, 24, 41, 41, 23, 4, 15, 27, 11, 38, 66, 24, 41, 64, 23, 49, 11, 12, 50, 23, 6, 48, 62, 41, 11, 16, 45, 5, 11, 49, 24, 12, 4, 11, 19, 62, 27, 48, 62, 64, 41, 23, 15, 27, 11, 68, 45, 23, 41, 4, 11, 12, 50, 23, 6, 48, 62, 41, 11, 16, 45, 45, 5, 11, 68, 41, 5, 11, 27, 62, 19, 23, 41, 68, 15, 27, 11, 68, 45, 23, 41, 4, 11, 12, 50, 23, 6, 48, 62, 41, 11, 16, 45, 45, 45, 5, 11, 68, 41, 5, 11, 27, 62, 19, 23, 41, 68, 15, 27, 11, 68, 45, 23, 41, 4, 11, 12, 50, 23, 6, 48, 62, 41, 11, 16, 45, 21, 5, 11, 65, 45, 64, 23, 11, 50, 23, 41, 59, 62, 41, 15, 27, 11, 38, 66, 24, 41, 64, 23, 49, 11, 12, 50, 23, 6, 48, 62, 41, 11, 16, 21, 5, 11, 68, 41, 5, 11, 27, 62, 19, 23, 41, 68, 15, 27, 11, 68, 45, 23, 41, 4, 11, 12, 50, 23, 6, 48, 62, 41, 11, 16, 21, 45, 5, 11, 68, 41, 5, 11, 27, 62, 19, 23, 41, 68, 15, 27, 11, 68, 45, 23, 41, 4, 11, 12, 50, 23, 6, 48, 62, 41, 11, 16, 21, 45, 45, 5, 11, 68, 41, 5, 11, 27, 62, 19, 23, 41, 68, 15, 27, 11, 68, 45, 23, 41, 4, 11, 12, 50, 23, 6, 48, 62, 41, 11, 16, 21, 45, 45, 45, 5, 11, 68, 41, 5, 11, 27, 62, 19, 23, 41, 68, 15, 27, 11, 68, 45, 23, 41, 4, 11, 12, 50, 23, 6, 48, 62, 41, 11, 16, 45, 16, 5, 11, 38, 66, 64, 23, 48, 50, 23, 64, 11, 50, 23, 41, 59, 62, 41, 15, 27, 11, 38, 66, 24, 41, 64, 23, 49, 11, 12, 50\n"
          ]
        }
      ],
      "source": [
        "print(*tokenized_text[:1000], sep=', ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Sequences 419072\n",
            "[68, 41, 23, 12, 24, 49, 23, 11, 0, 37, 4, 0, 11, 37, 41, 23, 65, 11, 27, 48, 66, 59, 62, 41, 11, 8, 45, 49, 49, 24, 27, 48, 41, 23, 48, 45, 66, 64, 43, 11, 12, 66, 49, 66, 6, 50, 66, 64, 57, 11, 64, 62, 19, 11, 4, 66, 41, 59, 11, 40, 41, 66, 27, 27, 62, 48, 11, 51, 11, 68, 24, 64, 49, 23, 6, 11, 0, 6, 24, 37, 49, 45, 27, 50, 62, 41, 27, 0, 11, 12, 66, 6, 4, 41, 45, 40, 50, 48, 2, 11, 52]\n"
          ]
        }
      ],
      "source": [
        "# Cada secuencia tendrá una longitud de max_context_size caracteres y el caracter siguiente será la etiqueta a predecir.\n",
        "tokenized_sequences = list()\n",
        "def create_seq(raw_text):\n",
        "   for i in range(0,len(raw_text)-max_context_size):\n",
        "     tokenized_sequences.append(raw_text[i:max_context_size+i+1])\n",
        "   print('Total Sequences',len(tokenized_sequences))\n",
        "create_seq(tokenized_text)\n",
        "print(tokenized_sequences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verifico la logitud de un tokenized_sequence\n",
        "len(tokenized_sequences[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# Separo en features y etiquetas\n",
        "tokenized_sequences = np.array(tokenized_sequences)\n",
        "X,y = tokenized_sequences[:,:-1], tokenized_sequences[:,-1]\n",
        "\n",
        "# Split (80% train, 20% valid)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train_tensor = torch.tensor(y_train.squeeze(), dtype=torch.long)\n",
        "\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.long)\n",
        "y_val_tensor = torch.tensor(y_val.squeeze(), dtype=torch.long)\n",
        "\n",
        "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_ds   = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KFAyA4zCWE-5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((335257, 100), (335257,), (83815, 100), (83815,))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qcKRl70HFTzG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[27  2 11 23 64 68 11 49 24 12  4 11 19 23 27 11 49 45 59 62] s, and lucy was like\n"
          ]
        }
      ],
      "source": [
        "print(X_train[0,-20:], \"\".join([idx2char[i] for i in X_train[0,-20:]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TVpLCKSZFXZO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11  \n"
          ]
        }
      ],
      "source": [
        "print(y_train[0], idx2char[y_train[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(chars_vocab)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Perplexity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def perplexity(loss_value: float) -> float:\n",
        "    try:\n",
        "        return math.exp(loss_value)\n",
        "    except OverflowError:\n",
        "        return float('inf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CharModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=5, hidden_dim=64, n_layers=2, dropout=0.2):\n",
        "        super(CharModel, self).__init__()\n",
        "\n",
        "        # Embedding:\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1, embedding_dim=embed_dim)\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, batch_first=True, dropout=dropout, num_layers=n_layers)\n",
        "\n",
        "        # Last dropout and Fully connected layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim//2)\n",
        "        self.fc2 = nn.Linear(hidden_dim//2, vocab_size+1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len)\n",
        "        x = self.embedding(x)  # => (batch, seq_len, embed_dim)\n",
        "        x, _ = self.lstm(x)    # => (batch, seq_len, hidden_dim)\n",
        "        # take only the last output\n",
        "        x = x[:, -1, :]        # => (batch, 1, hidden_dim)\n",
        "        x = F.relu(self.fc1(self.dropout(x))) # => (batch, hidden_dim//2)\n",
        "        logits = self.fc2(x)                  # (batch, vocab_size+1)\n",
        "        return logits\n",
        "\n",
        "    def predict(self,x):\n",
        "        logits = self.forward(x) # (batch, vocab_size+1)\n",
        "        y_pred = F.softmax(logits, dim=1) # (batch, vocab_size+1)\n",
        "        return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instancio el modelo, la función de pérdida y el optimizador\n",
        "# Se probaron varias configuraciones y esta dió resultados aceptables\n",
        "model = CharModel(vocab_size=vocab_size, embed_dim=20, hidden_dim=256, n_layers=2, dropout=0.2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 247.10818: 100%|██████████| 2620/2620 [00:41<00:00, 62.45it/s]\n",
            "val_loss 211.40832: 100%|██████████| 655/655 [00:04<00:00, 137.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30 | Train Loss: 1.931 | Train PPL: 6.897 | Val Loss: 1.652 | Val PPL: 5.218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 199.40420: 100%|██████████| 2620/2620 [00:41<00:00, 62.44it/s]\n",
            "val_loss 187.68996: 100%|██████████| 655/655 [00:04<00:00, 132.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/30 | Train Loss: 1.558 | Train PPL: 4.751 | Val Loss: 1.467 | Val PPL: 4.335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 184.65512: 100%|██████████| 2620/2620 [00:42<00:00, 61.05it/s]\n",
            "val_loss 179.26059: 100%|██████████| 655/655 [00:05<00:00, 130.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/30 | Train Loss: 1.443 | Train PPL: 4.234 | Val Loss: 1.401 | Val PPL: 4.059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 176.06218: 100%|██████████| 2620/2620 [00:43<00:00, 60.17it/s]\n",
            "val_loss 173.76856: 100%|██████████| 655/655 [00:04<00:00, 133.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/30 | Train Loss: 1.376 | Train PPL: 3.959 | Val Loss: 1.358 | Val PPL: 3.888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 170.37346: 100%|██████████| 2620/2620 [00:41<00:00, 62.83it/s]\n",
            "val_loss 170.32915: 100%|██████████| 655/655 [00:04<00:00, 135.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/30 | Train Loss: 1.331 | Train PPL: 3.787 | Val Loss: 1.331 | Val PPL: 3.785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 165.98482: 100%|██████████| 2620/2620 [00:41<00:00, 62.64it/s]\n",
            "val_loss 169.06971: 100%|██████████| 655/655 [00:04<00:00, 138.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/30 | Train Loss: 1.297 | Train PPL: 3.659 | Val Loss: 1.321 | Val PPL: 3.748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 162.75179: 100%|██████████| 2620/2620 [00:40<00:00, 64.00it/s]\n",
            "val_loss 166.82512: 100%|██████████| 655/655 [00:04<00:00, 146.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/30 | Train Loss: 1.272 | Train PPL: 3.568 | Val Loss: 1.304 | Val PPL: 3.683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 159.96658: 100%|██████████| 2620/2620 [00:41<00:00, 63.79it/s]\n",
            "val_loss 166.89374: 100%|██████████| 655/655 [00:04<00:00, 134.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/30 | Train Loss: 1.250 | Train PPL: 3.491 | Val Loss: 1.304 | Val PPL: 3.685\n",
            "\tInfo - Current epochs without validation metric improvement 1. 4 remaining before stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 157.47486: 100%|██████████| 2620/2620 [00:41<00:00, 62.98it/s]\n",
            "val_loss 165.22112: 100%|██████████| 655/655 [00:04<00:00, 135.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/30 | Train Loss: 1.231 | Train PPL: 3.423 | Val Loss: 1.291 | Val PPL: 3.637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 155.63858: 100%|██████████| 2620/2620 [00:42<00:00, 60.93it/s]\n",
            "val_loss 163.82508: 100%|██████████| 655/655 [00:04<00:00, 143.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/30 | Train Loss: 1.216 | Train PPL: 3.375 | Val Loss: 1.280 | Val PPL: 3.598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 153.57882: 100%|██████████| 2620/2620 [00:40<00:00, 64.98it/s]\n",
            "val_loss 164.24308: 100%|██████████| 655/655 [00:04<00:00, 140.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/30 | Train Loss: 1.200 | Train PPL: 3.321 | Val Loss: 1.284 | Val PPL: 3.609\n",
            "\tInfo - Current epochs without validation metric improvement 1. 4 remaining before stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 152.05589: 100%|██████████| 2620/2620 [00:38<00:00, 68.39it/s]\n",
            "val_loss 163.24759: 100%|██████████| 655/655 [00:04<00:00, 138.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/30 | Train Loss: 1.188 | Train PPL: 3.282 | Val Loss: 1.276 | Val PPL: 3.581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 150.64133: 100%|██████████| 2620/2620 [00:39<00:00, 66.20it/s]\n",
            "val_loss 163.71452: 100%|██████████| 655/655 [00:04<00:00, 158.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/30 | Train Loss: 1.177 | Train PPL: 3.245 | Val Loss: 1.279 | Val PPL: 3.594\n",
            "\tInfo - Current epochs without validation metric improvement 1. 4 remaining before stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 149.43090: 100%|██████████| 2620/2620 [00:38<00:00, 67.89it/s]\n",
            "val_loss 163.47897: 100%|██████████| 655/655 [00:05<00:00, 129.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/30 | Train Loss: 1.168 | Train PPL: 3.215 | Val Loss: 1.278 | Val PPL: 3.588\n",
            "\tInfo - Current epochs without validation metric improvement 2. 3 remaining before stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 148.06405: 100%|██████████| 2620/2620 [00:38<00:00, 67.73it/s]\n",
            "val_loss 163.19351: 100%|██████████| 655/655 [00:04<00:00, 143.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/30 | Train Loss: 1.157 | Train PPL: 3.181 | Val Loss: 1.275 | Val PPL: 3.580\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 147.21325: 100%|██████████| 2620/2620 [00:36<00:00, 70.92it/s]\n",
            "val_loss 164.04516: 100%|██████████| 655/655 [00:04<00:00, 153.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/30 | Train Loss: 1.150 | Train PPL: 3.160 | Val Loss: 1.282 | Val PPL: 3.604\n",
            "\tInfo - Current epochs without validation metric improvement 1. 4 remaining before stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 146.18640: 100%|██████████| 2620/2620 [00:37<00:00, 69.58it/s]\n",
            "val_loss 164.15057: 100%|██████████| 655/655 [00:04<00:00, 143.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/30 | Train Loss: 1.142 | Train PPL: 3.134 | Val Loss: 1.283 | Val PPL: 3.607\n",
            "\tInfo - Current epochs without validation metric improvement 2. 3 remaining before stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 145.10616: 100%|██████████| 2620/2620 [00:38<00:00, 68.89it/s]\n",
            "val_loss 163.44811: 100%|██████████| 655/655 [00:04<00:00, 154.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/30 | Train Loss: 1.134 | Train PPL: 3.108 | Val Loss: 1.277 | Val PPL: 3.587\n",
            "\tInfo - Current epochs without validation metric improvement 3. 2 remaining before stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 144.03813: 100%|██████████| 2620/2620 [00:36<00:00, 72.63it/s]\n",
            "val_loss 163.67888: 100%|██████████| 655/655 [00:04<00:00, 155.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/30 | Train Loss: 1.126 | Train PPL: 3.082 | Val Loss: 1.279 | Val PPL: 3.593\n",
            "\tInfo - Current epochs without validation metric improvement 4. 1 remaining before stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 143.19826: 100%|██████████| 2620/2620 [00:37<00:00, 70.49it/s]\n",
            "val_loss 163.76241: 100%|██████████| 655/655 [00:04<00:00, 143.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/30 | Train Loss: 1.119 | Train PPL: 3.062 | Val Loss: 1.280 | Val PPL: 3.596\n",
            "\tInfo - Training interrupted due to early stopping condition.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 30\n",
        "patience = 5\n",
        "patience_factor = 0.0001\n",
        "model_file = 'best_model.pt'\n",
        "\n",
        "# Historial de métricas\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"train_ppl\": [],\n",
        "    \"val_ppl\": [],\n",
        "    \"val_acc\": []\n",
        "}\n",
        "pt_epoch = 0\n",
        "best_model = 999999999\n",
        "# Set metric for callbacks\n",
        "best_eval = 999999999\n",
        "\n",
        "# enviamos el modelo al device\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # --- Entrenamiento ---\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    bar = tqdm(train_loader)\n",
        "    for i, batch in enumerate(bar):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        xb, yb = batch\n",
        "        xb, yb = xb.to(device), yb.to(device) # lo enviamos al device\n",
        "        y_pred = model(xb)  # => (batch, vocab_size+1)\n",
        "        loss = criterion(y_pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * xb.size(0)\n",
        "        # seteo descriptores en la barra\n",
        "        bar.set_description(f\"loss {train_loss/(i+1):.5f}\")\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_ds)\n",
        "    train_ppl = perplexity(avg_train_loss)\n",
        "\n",
        "    # --- Validación ---\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        bar = tqdm(val_loader)\n",
        "        for i, batch in enumerate(bar):\n",
        "            xb, yb = batch\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            y_pred = model(xb)\n",
        "            loss = criterion(y_pred, yb)\n",
        "            val_loss += loss.item() * xb.size(0)\n",
        "\n",
        "            preds = y_pred.argmax(dim=1) # Me quedo con la clase de mayor probabilidad\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "            bar.set_description(f\"val_loss {val_loss/(i+1):.5f}\")\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_ds)\n",
        "    val_ppl = perplexity(avg_val_loss)\n",
        "    val_acc = correct / total\n",
        "\n",
        "    # Guardar métricas\n",
        "    history[\"train_loss\"].append(avg_train_loss)\n",
        "    history[\"val_loss\"].append(avg_val_loss)\n",
        "    history[\"train_ppl\"].append(train_ppl)\n",
        "    history[\"val_ppl\"].append(val_ppl)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "          f\"Train Loss: {avg_train_loss:.3f} | Train PPL: {train_ppl:.3f} | \"\n",
        "          f\"Val Loss: {avg_val_loss:.3f} | Val PPL: {val_ppl:.3f}\"\n",
        "          )\n",
        "    \n",
        "    if val_ppl<best_model:\n",
        "        # Guardo el mejor modelo\n",
        "        torch.save(model.state_dict(), model_file)\n",
        "        best_model = val_ppl\n",
        "    ## Early stopping\n",
        "    if val_ppl<=best_eval*(1-patience_factor):\n",
        "        best_eval = val_ppl\n",
        "        pt_epoch = 0\n",
        "    else:\n",
        "        pt_epoch += 1\n",
        "        if pt_epoch>=patience:\n",
        "            print(f\"\\tInfo - Training interrupted due to early stopping condition.\")\n",
        "            break\n",
        "        else:\n",
        "            print(f\"\\tInfo - Current epochs without validation metric improvement {pt_epoch}. {patience-pt_epoch} remaining before stopping.\")\n",
        "\n",
        "# Al finalizar, cargo el mejor modelo\n",
        "model.load_state_dict(torch.load(model_file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Gráfico de épocas vs perplejidad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history[\"train_ppl\"], label=\"Train PPL\")\n",
        "plt.plot(history[\"val_ppl\"], label=\"Val PPL\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Perplexity\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "def encode(text,max_length=max_context_size):\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in text.lower()]\n",
        "    # Si tienen distinto largo\n",
        "    if len(encoded) < max_length: # Hago padding hasta max_len\n",
        "        encoded = [0] * (max_length - len(encoded)) + encoded\n",
        "    else: # O me quedo con los últimos max_len caracteres\n",
        "        encoded = encoded[-max_length:]\n",
        "   \n",
        "    return encoded\n",
        "\n",
        "def decode(idx):\n",
        "    return idx2char[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_next_char(model, human_text, max_len, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    # Encodeamos\n",
        "    encoded = encode(human_text,max_length=max_len)\n",
        "\n",
        "    x = torch.as_tensor([encoded], dtype=torch.long, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        y_hat = model.predict(x)  # (1, vocab_size+1)\n",
        "        idx = y_hat.argmax().item()\n",
        "\n",
        "        # Debemos buscar en el vocabulario el caracter\n",
        "        # que corresponde al indice (y_hat) predicho por le modelo\n",
        "        out_char = decode(idx)\n",
        "\n",
        "    return out_char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'g'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_next_char(model, 'Godalmin', max_len=max_context_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq_greedy(model, seed_text, max_length, n_chars, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model: modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_chars (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_chars\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# genero n_chars caracteres\n",
        "    for _ in range(n_chars):\n",
        "        c = predict_next_char(model, output_text, max_length, device=device)\n",
        "\t\t# Agrego el caracter a la frase predicha\n",
        "        output_text += c\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JoFqRC5pxzqS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'It was on the dark side of twilight when we got to be all the same things and the '"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='It was on the dark side of twilight when we got to b'\n",
        "generate_seq_greedy(model, input_text, max_length=max_context_size, n_chars=30, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'that was arthur had been so so'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='that was arthur'\n",
        "generate_seq_greedy(model, input_text, max_length=max_context_size, n_chars=15, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'late in the count in the strange things of the same '"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='la'\n",
        "generate_seq_greedy(model, input_text, max_length=max_context_size, n_chars=30, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'near the correct of the strange things of the '"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='near the correct'\n",
        "generate_seq_greedy(model, input_text, max_length=max_context_size, n_chars=30, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1.,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "    x = torch.as_tensor([encoded], dtype=torch.long, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      # first prediction\n",
        "      y_hat = model.predict(x).cpu()[0] # (1, vocab_size+1) => (vocab_size+1)\n",
        "\n",
        "      # get vocabulary size\n",
        "      vocab_size = y_hat.shape[0]\n",
        "\n",
        "      # initialize history\n",
        "      history_probs = [0]*num_beams\n",
        "      history_tokens = [encoded]*num_beams # 10 beams, 100 (max_context_size)\n",
        "      # select num_beams candidates\n",
        "      history_probs, history_tokens = select_candidates([y_hat], num_beams, vocab_size, history_probs,\n",
        "                                                        history_tokens, temp, mode)\n",
        "      # beam search loop\n",
        "      for i in range(num_words-1):\n",
        "\n",
        "        preds = []\n",
        "\n",
        "        for hist in history_tokens:\n",
        "\n",
        "          # actualizar secuencia de tokens\n",
        "          input_update = np.array([hist[i+1:]]).copy()\n",
        "          # predicción\n",
        "          x = torch.as_tensor(input_update, dtype=torch.long, device=device)\n",
        "          y_hat = model.predict(x).cpu()[0] # (1, vocab_size+1) => (vocab_size+1)\n",
        "\n",
        "          preds.append(y_hat)\n",
        "\n",
        "        history_probs, history_tokens = select_candidates(preds, num_beams, vocab_size, history_probs, history_tokens, temp, mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 6 41 45 21 45 49 62 40 62 11 48 66 11 12 66 65 62  5 35 11 50 62 11 27\n",
            " 23 45 68 43  9  9 11 60  4 66 24 11 65 24 27 48 11 50 23 21 62 11 48]\n",
            "privilege to come.” he said:-- “you must have t\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=30,input=\"privilege to come\", mode='det')\n",
        "print(salidas[0])\n",
        "print(''.join(decode(ch) for ch in salidas[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 6 41 45 21 45 49 62 40 62 11 48 66 11 12 66 65 62 11 48 66 11 48 50 62\n",
            " 11 49 23 48 48 62 41  2 11 23 64 68 11 45 11 59 64 66 19 11 48 50 23]\n",
            "privilege to come to the latter, and i know tha\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=30,input=\"privilege to come\", mode='sto', temp=1)\n",
        "print(salidas[0])\n",
        "print(''.join(decode(ch) for ch in salidas[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "P8HQoLhw-NYg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 6 41 45 21 45 49 62 40 62 11 48 66 11 12 66 65 62 11 48 66 11 48 50 62\n",
            " 11 19 45 64 68 66 19  2 11 23 64 68 11 48 50 62 41 62 11 45 27 11 64]\n",
            "privilege to come to the window, and there is n\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=30,input=\"privilege to come\", mode='sto', temp=0.5)\n",
        "print(salidas[0])\n",
        "print(''.join(decode(ch) for ch in salidas[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "2S3_I3S1W1Hm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 6 41 45 21 45 49 62 40 62 11 48 66 11 12 66 65 62 11 48 66 11 48 50 62\n",
            " 11 12 66 24 64 48  2 11 23 64 68 11 48 50 62 11 12 66 24 64 48 11 45]\n",
            "privilege to come to the count, and the count i\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=30,input=\"privilege to come\", mode='sto', temp=0.2)\n",
        "print(salidas[0])\n",
        "print(''.join(decode(ch) for ch in salidas[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[37 24 48 11 66 64 49  4 11 48 66 11 59 64 66 19 11 48 50 23 48 11  4 66\n",
            " 24 11 50 23 21 62 11 37 62 62 64 11 27 66 65 62 48 50 45 64 40 11]\n",
            "but only to know that you have been something \n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=30,input=\"but only to know\", mode='det')\n",
        "print(salidas[0])\n",
        "print(''.join(decode(ch) for ch in salidas[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[48 50 23 48 11 19 62 11 23 41 62 11 45 64 11 26 66 41 11 23 11 27 48 66\n",
            " 41 65  2 11 23 64 68 11 48 50 62 41 62 11 45 27 11 64 66 11 27 66 24 64\n",
            " 68 11 48 50 23 48 11 45]\n",
            "that we are in for a storm, and there is no sound that i\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=30,input=\"that we are in for a storm\", mode='sto', temp=0.5)\n",
        "print(salidas[0])\n",
        "print(''.join(decode(ch) for ch in salidas[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusiones\n",
        "\n",
        "En la prueba greedy, el modelo de predicción de caracteres termina armando palabras que parecen tener sentido, no tanto asi las oraciones que forma.  \n",
        "En ocasiones, cuando se pide una cantidad de caracteres elevadas, parece entrar en un circulo donde se repiten los caracteres.  \n",
        "También da la sensación de que tiene letras y secuencias que se repiten más. (ej. las secuencias strange, things y so aparecieron muchas veces)\n",
        "\n",
        "En las pruebas beam search, tanto en determinístico como en estocástico los caracteres formaron palabras existentes, igual que en el caso anterior, el sentido de la oración puede no ser del todo bueno.  \n",
        "En el estocástico, con una temperatura alta hay más variedad de resultados, al bajar la temperatura, los resultados que ofrece se repiten, incluso en la temperatura más baja, solo ofrece un par de resultados distintos.  \n",
        "También parece que hay secuencias de caracteres que tiende a devolver con mayor frecuencia.\n",
        "\n",
        "Es destacable que no vimos casi palabras desconocidas, aunque en el primer ejemplo determinístico, devolvió varios simbolos como predicciones, algunos que podrían ser correctos, otros que no tanto."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "B3_AP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
