{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Traductor\n",
    "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consignas\n",
    "Replicar y extender el traductor:\n",
    "- Replicar el modelo en PyTorch.\n",
    "- Extender el entrenamiento a más datos y tamaños de\n",
    "secuencias mayores.\n",
    "- Explorar el impacto de la cantidad de neuronas en\n",
    "las capas recurrentes.\n",
    "- Mostrar 5 ejemplos de traducciones generadas.\n",
    "- Extras que se pueden probar: Embeddings\n",
    "pre-entrenados para los dos idiomas; cambiar la\n",
    "estrategia de generación (por ejemplo muestreo\n",
    "aleatorio);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqO0PRcFsPTe"
   },
   "source": [
    "### Datos\n",
    "El objetivo es utilizar datos disponibles del Tatoeba Project de traducciones de texto en diferentes idiomas.  \n",
    "Se construirá un modelo traductor de inglés a español seq2seq utilizando encoder-decoder.  \n",
    "[LINK](https://www.manythings.org/anki/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion auxiliar para descargar el dataset\n",
    "def download_dataset(dataset_url: str, target_dir: str, check_dir: str | None = None, force: bool = False, tmp_file: str = \"tmp.zip\", unzip: bool = True):\n",
    "\n",
    "    if check_dir and os.path.isdir(check_dir) and not force:\n",
    "        print(\"Check folder already exists, nothing downloaded.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with requests.get(dataset_url, stream=True, allow_redirects=True) as response:\n",
    "            response.raise_for_status()  # Raise an exception for bad status codes\n",
    "\n",
    "            with open(tmp_file, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f\"File '{tmp_file}' downloaded successfully.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        if (os.path.isfile(tmp_file)):\n",
    "            os.remove(tmp_file)\n",
    "        raise(Exception(f\"Error downloading file: {e}\"))\n",
    "\n",
    "    if not unzip:\n",
    "        return\n",
    "    try:\n",
    "        with ZipFile(tmp_file, 'r') as zip_object:\n",
    "            zip_object.extractall(target_dir)\n",
    "        print(f\"Successfully extracted '{tmp_file}' to '{target_dir}'.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise(Exception(f\"Error: The file '{tmp_file}' was not found.\"))\n",
    "    except Exception as e:\n",
    "        raise(Exception(f\"An error occurred: {e}\"))\n",
    "    finally:\n",
    "        if (os.path.isfile(tmp_file)):\n",
    "            os.remove(tmp_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check folder already exists, nothing downloaded.\n"
     ]
    }
   ],
   "source": [
    "dataset_url = \"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
    "base_dir = \"./\"\n",
    "folder_dir = \"spa-eng\"\n",
    "download_dataset(dataset_url, base_dir, check_dir=folder_dir, tmp_file=\"spa-eng.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-9aNLZBDtA5J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows disponibles: 118964\n",
      "Cantidad de rows utilizadas: 6000\n"
     ]
    }
   ],
   "source": [
    "# dataset_file\n",
    "\n",
    "text_file = os.path.join(base_dir, folder_dir, \"spa.txt\")\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "# Por limitaciones de RAM no se leen todas las filas\n",
    "MAX_NUM_SENTENCES = 6000\n",
    "\n",
    "# Mezclar el dataset, forzar semilla siempre igual\n",
    "np.random.seed([40])\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "count = 0\n",
    "\n",
    "for line in lines:\n",
    "    count += 1\n",
    "    if count > MAX_NUM_SENTENCES:\n",
    "        break\n",
    "\n",
    "    # el tabulador señaliza la separación entre las oraciones \n",
    "    # en ambos idiomas\n",
    "    if '\\t' not in line: \n",
    "        continue\n",
    "\n",
    "    # Input sentence --> eng\n",
    "    # output --> spa\n",
    "    input_sentence, output = line.rstrip().split('\\t')\n",
    "\n",
    "    # output sentence (decoder_output) tiene <eos>\n",
    "    output_sentence = output + ' <eos>'\n",
    "    # output sentence input (decoder_input) tiene <sos>\n",
    "    output_sentence_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Cantidad de rows disponibles:\", len(lines))\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "93IGMKFb73q7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A deal is a deal.',\n",
       " 'Un trato es un trato. <eos>',\n",
       " '<sos> Un trato es un trato.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[0], output_sentences[0], output_sentences_inputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-ynUNP5xp6"
   },
   "source": [
    "### 2 - Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5WAZGOTfGyha"
   },
   "outputs": [],
   "source": [
    "# Definir el tamaño máximo del vocabulario\n",
    "MAX_VOCAB_SIZE = 8000\n",
    "# Vamos a necesitar un tokenizador para cada idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Tokenizar las palabras, similar a Tokenizer de Keras\n",
    "class Tokenizer():\n",
    "    def __init__(self, num_words: int | None = None, filters: str = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'):\n",
    "        self.num_words = num_words\n",
    "        self.filters = filters\n",
    "        self.word_index = {}\n",
    "\n",
    "    def __preprocess_text(self, text: str) -> list[str]:\n",
    "        text = ''.join(' ' if char in self.filters else char for char in text.lower())\n",
    "        return [word for word in text.split(' ') if word]\n",
    "\n",
    "    def fit_on_texts(self, input_sentences: list[str]) -> None:\n",
    "        if (len(self.word_index) != 0):\n",
    "            raise(Exception(\"Tokenizer has already been fit.\"))\n",
    "        counter = Counter()\n",
    "        for text in input_sentences:\n",
    "            sentence = self.__preprocess_text(text)\n",
    "            if not sentence: continue\n",
    "            counter.update(sentence)\n",
    "\n",
    "        most_common_n_words = counter.most_common(None if self.num_words is None else self.num_words - 1)\n",
    "\n",
    "        self.word_index = { word: i+1 for i, (word, _) in enumerate(most_common_n_words)}\n",
    "\n",
    "    def texts_to_sequences(self, input_sentences: list[str]):\n",
    "        if (len(self.word_index) == 0):\n",
    "            raise(Exception(\"Tokenizer has not been fit yet.\"))\n",
    "        input_integer_seq = []\n",
    "        for tokens in input_sentences:\n",
    "            tokens = self.__preprocess_text(tokens)\n",
    "            if not tokens: continue\n",
    "            sequence = [self.word_index[word] for word in tokens]\n",
    "            input_integer_seq.append(sequence)\n",
    "        return input_integer_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 3851\n",
      "Sentencia de entrada más larga: 32\n"
     ]
    }
   ],
   "source": [
    "# Defino una máxima cantidad de palabras a utilizar:\n",
    "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
    "# - Only the most common num_words-1 words will be kept.\n",
    "\n",
    "# tokenizador de inglés\n",
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Sentencia de entrada más larga:\", max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'to': 2,\n",
       " 'i': 3,\n",
       " 'you': 4,\n",
       " 'tom': 5,\n",
       " 'a': 6,\n",
       " 'is': 7,\n",
       " 'he': 8,\n",
       " 'in': 9,\n",
       " 'of': 10,\n",
       " 'that': 11,\n",
       " 'do': 12,\n",
       " 'was': 13,\n",
       " 'it': 14,\n",
       " 'my': 15,\n",
       " 'me': 16,\n",
       " 'this': 17,\n",
       " 'have': 18,\n",
       " 'she': 19,\n",
       " 'for': 20,\n",
       " 'what': 21,\n",
       " 'are': 22,\n",
       " \"don't\": 23,\n",
       " 'his': 24,\n",
       " 'mary': 25,\n",
       " 'on': 26,\n",
       " 'be': 27,\n",
       " 'we': 28,\n",
       " 'with': 29,\n",
       " 'your': 30,\n",
       " 'want': 31,\n",
       " 'and': 32,\n",
       " 'not': 33,\n",
       " \"i'm\": 34,\n",
       " 'know': 35,\n",
       " 'at': 36,\n",
       " 'like': 37,\n",
       " 'him': 38,\n",
       " 'go': 39,\n",
       " 'time': 40,\n",
       " 'her': 41,\n",
       " 'can': 42,\n",
       " 'has': 43,\n",
       " 'will': 44,\n",
       " 'all': 45,\n",
       " 'how': 46,\n",
       " 'about': 47,\n",
       " 'did': 48,\n",
       " 'very': 49,\n",
       " 'here': 50,\n",
       " 'there': 51,\n",
       " \"it's\": 52,\n",
       " 'as': 53,\n",
       " 'up': 54,\n",
       " \"didn't\": 55,\n",
       " 'think': 56,\n",
       " 'they': 57,\n",
       " 'had': 58,\n",
       " 'when': 59,\n",
       " \"can't\": 60,\n",
       " 'were': 61,\n",
       " 'no': 62,\n",
       " 'from': 63,\n",
       " 'if': 64,\n",
       " 'come': 65,\n",
       " 'see': 66,\n",
       " 'get': 67,\n",
       " 'good': 68,\n",
       " 'why': 69,\n",
       " \"doesn't\": 70,\n",
       " 'been': 71,\n",
       " 'an': 72,\n",
       " 'out': 73,\n",
       " 'by': 74,\n",
       " 'tell': 75,\n",
       " 'just': 76,\n",
       " 'please': 77,\n",
       " 'would': 78,\n",
       " 'home': 79,\n",
       " 'going': 80,\n",
       " 'much': 81,\n",
       " 'some': 82,\n",
       " 'but': 83,\n",
       " 'who': 84,\n",
       " 'than': 85,\n",
       " 'got': 86,\n",
       " 'day': 87,\n",
       " 'could': 88,\n",
       " 'us': 89,\n",
       " \"i'll\": 90,\n",
       " 'so': 91,\n",
       " \"you're\": 92,\n",
       " 'one': 93,\n",
       " 'something': 94,\n",
       " 'work': 95,\n",
       " 'need': 96,\n",
       " 'should': 97,\n",
       " 'help': 98,\n",
       " 'take': 99,\n",
       " 'money': 100,\n",
       " 'last': 101,\n",
       " 'am': 102,\n",
       " 'where': 103,\n",
       " 'our': 104,\n",
       " 'more': 105,\n",
       " 'does': 106,\n",
       " 'too': 107,\n",
       " 'car': 108,\n",
       " 'anything': 109,\n",
       " 'people': 110,\n",
       " 'make': 111,\n",
       " \"i've\": 112,\n",
       " 'give': 113,\n",
       " 'lot': 114,\n",
       " 'never': 115,\n",
       " \"isn't\": 116,\n",
       " \"he's\": 117,\n",
       " 'today': 118,\n",
       " 'said': 119,\n",
       " 'saw': 120,\n",
       " 'really': 121,\n",
       " 'now': 122,\n",
       " 'always': 123,\n",
       " 'three': 124,\n",
       " 'house': 125,\n",
       " 'school': 126,\n",
       " 'off': 127,\n",
       " 'long': 128,\n",
       " \"tom's\": 129,\n",
       " \"let's\": 130,\n",
       " 'father': 131,\n",
       " 'two': 132,\n",
       " 'new': 133,\n",
       " 'say': 134,\n",
       " 'little': 135,\n",
       " 'told': 136,\n",
       " 'every': 137,\n",
       " 'made': 138,\n",
       " 'nothing': 139,\n",
       " 'old': 140,\n",
       " 'wanted': 141,\n",
       " 'thought': 142,\n",
       " 'still': 143,\n",
       " 'any': 144,\n",
       " 'must': 145,\n",
       " 'man': 146,\n",
       " 'only': 147,\n",
       " 'eat': 148,\n",
       " 'way': 149,\n",
       " 'love': 150,\n",
       " 'well': 151,\n",
       " 'boston': 152,\n",
       " 'book': 153,\n",
       " 'or': 154,\n",
       " 'went': 155,\n",
       " 'into': 156,\n",
       " 'speak': 157,\n",
       " 'french': 158,\n",
       " 'room': 159,\n",
       " 'came': 160,\n",
       " \"we're\": 161,\n",
       " 'read': 162,\n",
       " 'many': 163,\n",
       " 'left': 164,\n",
       " 'look': 165,\n",
       " 'children': 166,\n",
       " 'talk': 167,\n",
       " 'right': 168,\n",
       " 'over': 169,\n",
       " 'asked': 170,\n",
       " 'put': 171,\n",
       " 'night': 172,\n",
       " 'friends': 173,\n",
       " 'back': 174,\n",
       " \"i'd\": 175,\n",
       " 'english': 176,\n",
       " 'wants': 177,\n",
       " \"that's\": 178,\n",
       " 'leave': 179,\n",
       " 'used': 180,\n",
       " 'tomorrow': 181,\n",
       " 'morning': 182,\n",
       " 'job': 183,\n",
       " 'understand': 184,\n",
       " 'better': 185,\n",
       " 'dog': 186,\n",
       " 'lost': 187,\n",
       " \"what's\": 188,\n",
       " 'before': 189,\n",
       " \"there's\": 190,\n",
       " 'again': 191,\n",
       " \"won't\": 192,\n",
       " 'stay': 193,\n",
       " 'may': 194,\n",
       " 'yesterday': 195,\n",
       " 'soon': 196,\n",
       " 'them': 197,\n",
       " 'next': 198,\n",
       " 'let': 199,\n",
       " 'name': 200,\n",
       " 'feel': 201,\n",
       " 'first': 202,\n",
       " 'done': 203,\n",
       " 'friend': 204,\n",
       " 'late': 205,\n",
       " 'play': 206,\n",
       " 'keep': 207,\n",
       " 'call': 208,\n",
       " 'took': 209,\n",
       " 'live': 210,\n",
       " 'hard': 211,\n",
       " 'idea': 212,\n",
       " 'ask': 213,\n",
       " 'sure': 214,\n",
       " \"mary's\": 215,\n",
       " \"she's\": 216,\n",
       " 'happened': 217,\n",
       " 'year': 218,\n",
       " 'years': 219,\n",
       " 'doing': 220,\n",
       " 'down': 221,\n",
       " 'learn': 222,\n",
       " 'few': 223,\n",
       " 'wrong': 224,\n",
       " 'mother': 225,\n",
       " 'after': 226,\n",
       " 'because': 227,\n",
       " 'stop': 228,\n",
       " 'remember': 229,\n",
       " 'kind': 230,\n",
       " 'everything': 231,\n",
       " 'away': 232,\n",
       " 'other': 233,\n",
       " 'teacher': 234,\n",
       " 'boy': 235,\n",
       " 'their': 236,\n",
       " 'door': 237,\n",
       " 'party': 238,\n",
       " 'find': 239,\n",
       " 'enough': 240,\n",
       " 'hear': 241,\n",
       " 'happy': 242,\n",
       " 'heard': 243,\n",
       " 'these': 244,\n",
       " 'train': 245,\n",
       " 'letter': 246,\n",
       " 'buy': 247,\n",
       " 'tired': 248,\n",
       " 'young': 249,\n",
       " 'alone': 250,\n",
       " 'around': 251,\n",
       " 'while': 252,\n",
       " 'days': 253,\n",
       " 'watch': 254,\n",
       " 'same': 255,\n",
       " 'bought': 256,\n",
       " 'truth': 257,\n",
       " 'almost': 258,\n",
       " \"you'll\": 259,\n",
       " 'meeting': 260,\n",
       " \"couldn't\": 261,\n",
       " 'busy': 262,\n",
       " \"aren't\": 263,\n",
       " 'gave': 264,\n",
       " 'met': 265,\n",
       " 'since': 266,\n",
       " 'food': 267,\n",
       " 'girl': 268,\n",
       " 'found': 269,\n",
       " 'true': 270,\n",
       " 'believe': 271,\n",
       " 'try': 272,\n",
       " 'already': 273,\n",
       " 'five': 274,\n",
       " 'anyone': 275,\n",
       " 'sleep': 276,\n",
       " 'able': 277,\n",
       " 'week': 278,\n",
       " 'problem': 279,\n",
       " 'without': 280,\n",
       " 'looking': 281,\n",
       " 'parents': 282,\n",
       " 'wait': 283,\n",
       " 'hope': 284,\n",
       " 'happen': 285,\n",
       " 'use': 286,\n",
       " 'brother': 287,\n",
       " \"wasn't\": 288,\n",
       " 'water': 289,\n",
       " 'john': 290,\n",
       " 'best': 291,\n",
       " 'wife': 292,\n",
       " 'beautiful': 293,\n",
       " 'big': 294,\n",
       " \"we'll\": 295,\n",
       " \"they're\": 296,\n",
       " 'town': 297,\n",
       " 'swim': 298,\n",
       " 'study': 299,\n",
       " 'care': 300,\n",
       " 'bed': 301,\n",
       " 'knew': 302,\n",
       " 'person': 303,\n",
       " 'eating': 304,\n",
       " 'fell': 305,\n",
       " 'ate': 306,\n",
       " 'wish': 307,\n",
       " 'monday': 308,\n",
       " 'often': 309,\n",
       " 'police': 310,\n",
       " 'walk': 311,\n",
       " 'important': 312,\n",
       " 'being': 313,\n",
       " 'word': 314,\n",
       " 'things': 315,\n",
       " 'having': 316,\n",
       " 'woman': 317,\n",
       " 'sister': 318,\n",
       " 'drink': 319,\n",
       " 'child': 320,\n",
       " 'pay': 321,\n",
       " 'doctor': 322,\n",
       " 'mind': 323,\n",
       " 'knows': 324,\n",
       " 'bad': 325,\n",
       " 'another': 326,\n",
       " 'cold': 327,\n",
       " 'open': 328,\n",
       " 'likes': 329,\n",
       " 'those': 330,\n",
       " 'else': 331,\n",
       " 'such': 332,\n",
       " \"you've\": 333,\n",
       " 'show': 334,\n",
       " 'students': 335,\n",
       " 'decided': 336,\n",
       " 'ever': 337,\n",
       " 'seen': 338,\n",
       " 'thing': 339,\n",
       " 'looks': 340,\n",
       " 'hurt': 341,\n",
       " 'spend': 342,\n",
       " 'getting': 343,\n",
       " 'early': 344,\n",
       " 'talking': 345,\n",
       " 'start': 346,\n",
       " 'looked': 347,\n",
       " 'trouble': 348,\n",
       " 'bus': 349,\n",
       " 'full': 350,\n",
       " 'together': 351,\n",
       " 'ago': 352,\n",
       " 'homework': 353,\n",
       " 'japanese': 354,\n",
       " 'rain': 355,\n",
       " 'accident': 356,\n",
       " 'visit': 357,\n",
       " 'red': 358,\n",
       " 'trying': 359,\n",
       " 'goes': 360,\n",
       " 'cat': 361,\n",
       " 'seems': 362,\n",
       " 'even': 363,\n",
       " 'working': 364,\n",
       " \"wouldn't\": 365,\n",
       " 'both': 366,\n",
       " 'easy': 367,\n",
       " 'each': 368,\n",
       " 'own': 369,\n",
       " 'coming': 370,\n",
       " 'far': 371,\n",
       " 'married': 372,\n",
       " 'nobody': 373,\n",
       " 'coffee': 374,\n",
       " 'great': 375,\n",
       " 'which': 376,\n",
       " 'someone': 377,\n",
       " 'playing': 378,\n",
       " 'table': 379,\n",
       " 'son': 380,\n",
       " 'life': 381,\n",
       " 'thinking': 382,\n",
       " 'speaking': 383,\n",
       " 'miss': 384,\n",
       " 'under': 385,\n",
       " 'tv': 386,\n",
       " 'forget': 387,\n",
       " 'longer': 388,\n",
       " 'dream': 389,\n",
       " 'everyone': 390,\n",
       " 'matter': 391,\n",
       " 'books': 392,\n",
       " 'favorite': 393,\n",
       " 'broke': 394,\n",
       " 'most': 395,\n",
       " '30': 396,\n",
       " \"hasn't\": 397,\n",
       " 'lunch': 398,\n",
       " 'hours': 399,\n",
       " 'arrived': 400,\n",
       " 'fish': 401,\n",
       " 'write': 402,\n",
       " 'key': 403,\n",
       " 'world': 404,\n",
       " 'felt': 405,\n",
       " 'river': 406,\n",
       " 'mean': 407,\n",
       " 'yet': 408,\n",
       " 'story': 409,\n",
       " 'talked': 410,\n",
       " 'women': 411,\n",
       " 'says': 412,\n",
       " 'age': 413,\n",
       " 'girlfriend': 414,\n",
       " 'quit': 415,\n",
       " 'become': 416,\n",
       " 'hot': 417,\n",
       " 'black': 418,\n",
       " 'christmas': 419,\n",
       " 'minutes': 420,\n",
       " 'plane': 421,\n",
       " 'gone': 422,\n",
       " 'dollars': 423,\n",
       " 'afraid': 424,\n",
       " 'six': 425,\n",
       " 'anymore': 426,\n",
       " 'making': 427,\n",
       " 'answer': 428,\n",
       " 'picture': 429,\n",
       " 'angry': 430,\n",
       " 'cake': 431,\n",
       " 'finish': 432,\n",
       " 'explain': 433,\n",
       " 'shoes': 434,\n",
       " 'window': 435,\n",
       " 'japan': 436,\n",
       " 'hate': 437,\n",
       " 'hour': 438,\n",
       " 'paid': 439,\n",
       " 'street': 440,\n",
       " 'thanks': 441,\n",
       " 'sit': 442,\n",
       " 'drive': 443,\n",
       " 'class': 444,\n",
       " 'music': 445,\n",
       " 'rich': 446,\n",
       " 'lives': 447,\n",
       " 'possible': 448,\n",
       " 'hit': 449,\n",
       " 'through': 450,\n",
       " 'hand': 451,\n",
       " 'might': 452,\n",
       " 'news': 453,\n",
       " 'question': 454,\n",
       " 'family': 455,\n",
       " 'clean': 456,\n",
       " 'station': 457,\n",
       " 'shopping': 458,\n",
       " 'then': 459,\n",
       " 'hungry': 460,\n",
       " 'office': 461,\n",
       " 'noise': 462,\n",
       " 'kill': 463,\n",
       " '2': 464,\n",
       " 'change': 465,\n",
       " 'once': 466,\n",
       " 'plan': 467,\n",
       " 'quite': 468,\n",
       " 'situation': 469,\n",
       " 'mine': 470,\n",
       " 'until': 471,\n",
       " 'wine': 472,\n",
       " 'began': 473,\n",
       " 'city': 474,\n",
       " 'waiting': 475,\n",
       " 'present': 476,\n",
       " 'yourself': 477,\n",
       " 'swimming': 478,\n",
       " 'glad': 479,\n",
       " \"haven't\": 480,\n",
       " 'died': 481,\n",
       " 'needs': 482,\n",
       " 'small': 483,\n",
       " 'pretty': 484,\n",
       " 'stopped': 485,\n",
       " 'hotel': 486,\n",
       " 'turn': 487,\n",
       " 'sad': 488,\n",
       " 'keys': 489,\n",
       " 'game': 490,\n",
       " 'advice': 491,\n",
       " 'decision': 492,\n",
       " 'fun': 493,\n",
       " 'thirty': 494,\n",
       " 'tried': 495,\n",
       " 'fast': 496,\n",
       " 'summer': 497,\n",
       " 'sick': 498,\n",
       " 'birthday': 499,\n",
       " 'caught': 500,\n",
       " 'tonight': 501,\n",
       " 'interesting': 502,\n",
       " 'baby': 503,\n",
       " 'weather': 504,\n",
       " 'prefer': 505,\n",
       " 'studying': 506,\n",
       " 'expect': 507,\n",
       " 'usually': 508,\n",
       " 'finished': 509,\n",
       " 'thank': 510,\n",
       " 'finally': 511,\n",
       " 'dinner': 512,\n",
       " 'pass': 513,\n",
       " 'hands': 514,\n",
       " 'sing': 515,\n",
       " 'sitting': 516,\n",
       " 'box': 517,\n",
       " 'tennis': 518,\n",
       " 'himself': 519,\n",
       " 'kids': 520,\n",
       " 'large': 521,\n",
       " 'sat': 522,\n",
       " 'eyes': 523,\n",
       " 'older': 524,\n",
       " 'difficult': 525,\n",
       " 'snow': 526,\n",
       " 'herself': 527,\n",
       " 'started': 528,\n",
       " 'test': 529,\n",
       " 'part': 530,\n",
       " 'hospital': 531,\n",
       " 'mistake': 532,\n",
       " 'worked': 533,\n",
       " 'yours': 534,\n",
       " 'place': 535,\n",
       " 'telephone': 536,\n",
       " 'high': 537,\n",
       " 'death': 538,\n",
       " 'cost': 539,\n",
       " 'wearing': 540,\n",
       " 'stand': 541,\n",
       " 'ten': 542,\n",
       " 'showed': 543,\n",
       " 'crazy': 544,\n",
       " 'others': 545,\n",
       " 'blame': 546,\n",
       " 'fight': 547,\n",
       " 'stupid': 548,\n",
       " 'tree': 549,\n",
       " 'surprised': 550,\n",
       " 'bicycle': 551,\n",
       " 'whether': 552,\n",
       " 'hair': 553,\n",
       " 'hold': 554,\n",
       " 'milk': 555,\n",
       " 'follow': 556,\n",
       " 'short': 557,\n",
       " 'dead': 558,\n",
       " 'takes': 559,\n",
       " 'shirt': 560,\n",
       " 'nice': 561,\n",
       " 'glass': 562,\n",
       " 'saying': 563,\n",
       " 'catch': 564,\n",
       " 'advised': 565,\n",
       " 'changed': 566,\n",
       " 'ready': 567,\n",
       " 'tokyo': 568,\n",
       " 'traffic': 569,\n",
       " 'canadian': 570,\n",
       " 'comes': 571,\n",
       " 'wrote': 572,\n",
       " 'tall': 573,\n",
       " 'needed': 574,\n",
       " 'words': 575,\n",
       " 'played': 576,\n",
       " 'crying': 577,\n",
       " 'smoking': 578,\n",
       " 'heart': 579,\n",
       " 'movie': 580,\n",
       " 'earth': 581,\n",
       " 'war': 582,\n",
       " 'floor': 583,\n",
       " 'kitchen': 584,\n",
       " 'dogs': 585,\n",
       " 'husband': 586,\n",
       " \"we've\": 587,\n",
       " 'close': 588,\n",
       " 'paper': 589,\n",
       " 'cut': 590,\n",
       " 'moment': 591,\n",
       " 'lived': 592,\n",
       " 'everybody': 593,\n",
       " 'park': 594,\n",
       " 'leg': 595,\n",
       " 'cannot': 596,\n",
       " 'killed': 597,\n",
       " 'spent': 598,\n",
       " 'against': 599,\n",
       " 'listen': 600,\n",
       " 'daughter': 601,\n",
       " 'lose': 602,\n",
       " 'speaks': 603,\n",
       " 'expected': 604,\n",
       " 'times': 605,\n",
       " 'perfect': 606,\n",
       " 'later': 607,\n",
       " 'wear': 608,\n",
       " 'half': 609,\n",
       " 'myself': 610,\n",
       " 'clothes': 611,\n",
       " 'cup': 612,\n",
       " 'along': 613,\n",
       " 'brought': 614,\n",
       " 'different': 615,\n",
       " 'eggs': 616,\n",
       " 'ahead': 617,\n",
       " 'sometimes': 618,\n",
       " 'thinks': 619,\n",
       " 'closed': 620,\n",
       " 'meat': 621,\n",
       " 'walked': 622,\n",
       " 'cry': 623,\n",
       " 'worry': 624,\n",
       " 'quickly': 625,\n",
       " 'during': 626,\n",
       " 'hurry': 627,\n",
       " 'bring': 628,\n",
       " 'dangerous': 629,\n",
       " 'strong': 630,\n",
       " 'point': 631,\n",
       " 'works': 632,\n",
       " 'beach': 633,\n",
       " 'company': 634,\n",
       " 'easily': 635,\n",
       " 'travel': 636,\n",
       " 'phone': 637,\n",
       " 'laughing': 638,\n",
       " 'figure': 639,\n",
       " 'arrive': 640,\n",
       " 'harder': 641,\n",
       " 'ran': 642,\n",
       " 'die': 643,\n",
       " 'hat': 644,\n",
       " 'minute': 645,\n",
       " 'lawyer': 646,\n",
       " 'flowers': 647,\n",
       " 'bath': 648,\n",
       " \"who's\": 649,\n",
       " 'meet': 650,\n",
       " 'sound': 651,\n",
       " 'vacation': 652,\n",
       " 'end': 653,\n",
       " 'born': 654,\n",
       " 'worse': 655,\n",
       " 'reason': 656,\n",
       " 'golf': 657,\n",
       " 'ice': 658,\n",
       " 'drunk': 659,\n",
       " 'weight': 660,\n",
       " 'cook': 661,\n",
       " 'tea': 662,\n",
       " 'walking': 663,\n",
       " 'called': 664,\n",
       " 'face': 665,\n",
       " 'fall': 666,\n",
       " 'hide': 667,\n",
       " 'dress': 668,\n",
       " 'dark': 669,\n",
       " 'wall': 670,\n",
       " 'restaurant': 671,\n",
       " 'dictionary': 672,\n",
       " 'bit': 673,\n",
       " 'deep': 674,\n",
       " 'second': 675,\n",
       " 'asleep': 676,\n",
       " 'taking': 677,\n",
       " \"where's\": 678,\n",
       " 'its': 679,\n",
       " 'order': 680,\n",
       " 'learned': 681,\n",
       " 'neighbors': 682,\n",
       " 'singing': 683,\n",
       " 'borrow': 684,\n",
       " 'real': 685,\n",
       " 'reading': 686,\n",
       " 'deal': 687,\n",
       " 'concert': 688,\n",
       " 'seemed': 689,\n",
       " 'pants': 690,\n",
       " 'secret': 691,\n",
       " 'serious': 692,\n",
       " 'smoke': 693,\n",
       " 'country': 694,\n",
       " 'fat': 695,\n",
       " 'listening': 696,\n",
       " 'mad': 697,\n",
       " 'given': 698,\n",
       " 'loves': 699,\n",
       " 'funny': 700,\n",
       " 'sun': 701,\n",
       " 'kyoto': 702,\n",
       " 'fact': 703,\n",
       " 'head': 704,\n",
       " 'stayed': 705,\n",
       " 'rather': 706,\n",
       " 'refused': 707,\n",
       " 'maybe': 708,\n",
       " 'terrible': 709,\n",
       " 'pain': 710,\n",
       " 'prison': 711,\n",
       " 'policeman': 712,\n",
       " 'succeed': 713,\n",
       " 'light': 714,\n",
       " 'feelings': 715,\n",
       " 'regret': 716,\n",
       " 'single': 717,\n",
       " 'weeks': 718,\n",
       " 'trip': 719,\n",
       " 'australia': 720,\n",
       " 'bag': 721,\n",
       " 'arm': 722,\n",
       " 'teach': 723,\n",
       " \"he'll\": 724,\n",
       " 'whose': 725,\n",
       " 'sorry': 726,\n",
       " 'piano': 727,\n",
       " 'free': 728,\n",
       " 'inside': 729,\n",
       " 'problems': 730,\n",
       " 'boys': 731,\n",
       " 'grandfather': 732,\n",
       " 'windows': 733,\n",
       " 'raining': 734,\n",
       " 'living': 735,\n",
       " 'four': 736,\n",
       " 'song': 737,\n",
       " 'radio': 738,\n",
       " 'helped': 739,\n",
       " 'dressed': 740,\n",
       " 'ship': 741,\n",
       " 'boss': 742,\n",
       " 'mouth': 743,\n",
       " \"it'll\": 744,\n",
       " 'soccer': 745,\n",
       " 'drinking': 746,\n",
       " 'apples': 747,\n",
       " 'interested': 748,\n",
       " 'canada': 749,\n",
       " 'warned': 750,\n",
       " 'fire': 751,\n",
       " 'near': 752,\n",
       " 'mountain': 753,\n",
       " 'seat': 754,\n",
       " 'apple': 755,\n",
       " 'eaten': 756,\n",
       " 'popular': 757,\n",
       " 'paint': 758,\n",
       " 'watching': 759,\n",
       " 'touched': 760,\n",
       " 'across': 761,\n",
       " 'stood': 762,\n",
       " 'cried': 763,\n",
       " 'worried': 764,\n",
       " 'mistakes': 765,\n",
       " 'beer': 766,\n",
       " 'learning': 767,\n",
       " 'chinese': 768,\n",
       " 'thousand': 769,\n",
       " 'grandmother': 770,\n",
       " 'bottle': 771,\n",
       " 'liked': 772,\n",
       " 'wonderful': 773,\n",
       " 'airport': 774,\n",
       " 'air': 775,\n",
       " 'address': 776,\n",
       " 'flight': 777,\n",
       " 'run': 778,\n",
       " 'guys': 779,\n",
       " 'accused': 780,\n",
       " 'report': 781,\n",
       " 'stolen': 782,\n",
       " \"shouldn't\": 783,\n",
       " 'student': 784,\n",
       " 'kept': 785,\n",
       " 'less': 786,\n",
       " 'player': 787,\n",
       " 'smile': 788,\n",
       " 'breakfast': 789,\n",
       " 'leaving': 790,\n",
       " 'fine': 791,\n",
       " 'bench': 792,\n",
       " 'passed': 793,\n",
       " 'moved': 794,\n",
       " 'men': 795,\n",
       " 'planning': 796,\n",
       " 'sunday': 797,\n",
       " 'covered': 798,\n",
       " 'fair': 799,\n",
       " 'ride': 800,\n",
       " 'break': 801,\n",
       " 'store': 802,\n",
       " \"he'd\": 803,\n",
       " 'weird': 804,\n",
       " 'enemy': 805,\n",
       " \"you'd\": 806,\n",
       " 'guitar': 807,\n",
       " 'written': 808,\n",
       " 'pie': 809,\n",
       " 'basket': 810,\n",
       " 'fruit': 811,\n",
       " 'tie': 812,\n",
       " 'bedroom': 813,\n",
       " 'whatever': 814,\n",
       " 'doubt': 815,\n",
       " 'somebody': 816,\n",
       " 'invited': 817,\n",
       " 'horse': 818,\n",
       " 'kissing': 819,\n",
       " 'math': 820,\n",
       " 'straight': 821,\n",
       " 'mom': 822,\n",
       " 'actually': 823,\n",
       " 'hole': 824,\n",
       " 'fly': 825,\n",
       " 'happening': 826,\n",
       " 'wallet': 827,\n",
       " 'supermarket': 828,\n",
       " 'girls': 829,\n",
       " 'sight': 830,\n",
       " 'choose': 831,\n",
       " 'month': 832,\n",
       " 'road': 833,\n",
       " \"hadn't\": 834,\n",
       " 'blood': 835,\n",
       " 'loud': 836,\n",
       " 'success': 837,\n",
       " 'sign': 838,\n",
       " 'absolutely': 839,\n",
       " 'wash': 840,\n",
       " 'outside': 841,\n",
       " 'suddenly': 842,\n",
       " 'rest': 843,\n",
       " 'front': 844,\n",
       " 'count': 845,\n",
       " 'date': 846,\n",
       " 'sooner': 847,\n",
       " 'speech': 848,\n",
       " 'forgot': 849,\n",
       " 'disappointed': 850,\n",
       " 'afternoon': 851,\n",
       " 'begin': 852,\n",
       " 'broken': 853,\n",
       " 'none': 854,\n",
       " 'enjoy': 855,\n",
       " 'perhaps': 856,\n",
       " 'exactly': 857,\n",
       " 'also': 858,\n",
       " 'smiled': 859,\n",
       " 'innocent': 860,\n",
       " 'club': 861,\n",
       " 'experience': 862,\n",
       " 'yen': 863,\n",
       " 'known': 864,\n",
       " 'color': 865,\n",
       " 'italy': 866,\n",
       " 'marry': 867,\n",
       " 'solve': 868,\n",
       " 'forever': 869,\n",
       " 'bother': 870,\n",
       " 'science': 871,\n",
       " 'kid': 872,\n",
       " 'voice': 873,\n",
       " 'plays': 874,\n",
       " 'seem': 875,\n",
       " 'abroad': 876,\n",
       " 'composition': 877,\n",
       " 'plans': 878,\n",
       " 'danced': 879,\n",
       " 'beginning': 880,\n",
       " '10': 881,\n",
       " 'team': 882,\n",
       " 'politics': 883,\n",
       " 'american': 884,\n",
       " 'osaka': 885,\n",
       " 'white': 886,\n",
       " 'lend': 887,\n",
       " 'failed': 888,\n",
       " \"must've\": 889,\n",
       " 'german': 890,\n",
       " 'noticed': 891,\n",
       " 'eight': 892,\n",
       " 'share': 893,\n",
       " 'lake': 894,\n",
       " 'ought': 895,\n",
       " 'lay': 896,\n",
       " 'certain': 897,\n",
       " 'latin': 898,\n",
       " 'wonder': 899,\n",
       " 'ticket': 900,\n",
       " 'trust': 901,\n",
       " 'computer': 902,\n",
       " 'guy': 903,\n",
       " 'received': 904,\n",
       " 'heavy': 905,\n",
       " 'laughed': 906,\n",
       " 'promise': 907,\n",
       " 'staying': 908,\n",
       " 'sent': 909,\n",
       " 'strange': 910,\n",
       " 'france': 911,\n",
       " 'crowd': 912,\n",
       " 'seven': 913,\n",
       " 'touch': 914,\n",
       " 'feet': 915,\n",
       " 'dishes': 916,\n",
       " 'farm': 917,\n",
       " 'wondered': 918,\n",
       " 'hobby': 919,\n",
       " 'fingers': 920,\n",
       " 'calling': 921,\n",
       " 'past': 922,\n",
       " 'cheese': 923,\n",
       " 'gift': 924,\n",
       " 'purpose': 925,\n",
       " 'position': 926,\n",
       " 'accept': 927,\n",
       " 'escape': 928,\n",
       " 'wherever': 929,\n",
       " 'introduced': 930,\n",
       " 'classroom': 931,\n",
       " 'visited': 932,\n",
       " 'winter': 933,\n",
       " 'ring': 934,\n",
       " 'india': 935,\n",
       " 'months': 936,\n",
       " 'pick': 937,\n",
       " 'choice': 938,\n",
       " 'became': 939,\n",
       " 'won': 940,\n",
       " 'nine': 941,\n",
       " 'scared': 942,\n",
       " 'bet': 943,\n",
       " 'desk': 944,\n",
       " 'join': 945,\n",
       " 'taxi': 946,\n",
       " 'joke': 947,\n",
       " 'empty': 948,\n",
       " 'jumped': 949,\n",
       " 'cooking': 950,\n",
       " 'decide': 951,\n",
       " 'safe': 952,\n",
       " 'size': 953,\n",
       " 'taken': 954,\n",
       " 'somewhere': 955,\n",
       " 'shut': 956,\n",
       " 'fool': 957,\n",
       " 'either': 958,\n",
       " 'guilty': 959,\n",
       " 'relax': 960,\n",
       " 'umbrella': 961,\n",
       " 'friendship': 962,\n",
       " 'glasses': 963,\n",
       " 'yellow': 964,\n",
       " 'feels': 965,\n",
       " 'wishes': 966,\n",
       " 'feeling': 967,\n",
       " 'weekend': 968,\n",
       " 'accidents': 969,\n",
       " 'matters': 970,\n",
       " 'ill': 971,\n",
       " 'wake': 972,\n",
       " 'god': 973,\n",
       " 'knife': 974,\n",
       " 'excuse': 975,\n",
       " 'jacket': 976,\n",
       " 'cream': 977,\n",
       " 'correct': 978,\n",
       " 'lucky': 979,\n",
       " 'library': 980,\n",
       " 'sea': 981,\n",
       " 'opinion': 982,\n",
       " 'joking': 983,\n",
       " 'bread': 984,\n",
       " 'turned': 985,\n",
       " 'medicine': 986,\n",
       " 'makes': 987,\n",
       " 'operation': 988,\n",
       " 'immediately': 989,\n",
       " 'cars': 990,\n",
       " 'mail': 991,\n",
       " 'information': 992,\n",
       " 'goal': 993,\n",
       " 'bike': 994,\n",
       " 'anybody': 995,\n",
       " 'non': 996,\n",
       " 'ability': 997,\n",
       " 'painted': 998,\n",
       " 'fifteen': 999,\n",
       " 'shy': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "zBzdKiTVIBYY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 5721\n",
      "Sentencia de salida más larga: 36\n"
     ]
    }
   ],
   "source": [
    "# tokenizador de español\n",
    "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
    "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
    "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
    "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
    "\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) \n",
    "# Se suma 1 para incluir el token de palabra desconocida\n",
    "\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Sentencia de salida más larga:\", max_out_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xqb8ZJ4sJHgv"
   },
   "source": [
    "Como era de esperarse, las sentencias en castellano son más largas que en inglés, y lo mismo sucede con su vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "pgLC706EQx3p"
   },
   "outputs": [],
   "source": [
    "# Por una cuestion de que no explote la RAM se limitará el tamaño de las sentencias de entrada\n",
    "# a la mitad:\n",
    "max_input_len = 16\n",
    "max_out_len = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGOn9N57IuYz"
   },
   "source": [
    "A la hora de realizar padding es importante tener en cuenta que en el encoder los ceros se agregan al comienzo y en el decoder al final.  \n",
    "Esto es porque la salida del encoder está basado en las últimas palabras de la sentencia (son las más importantes), mientras que en el decoder está basado en el comienzo de la secuencia de salida ya que es la realimentación del sistema y termina con fin de sentencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, maxlen=None, dtype='int32', padding_pre=True, truncating_pre=True, value=0.0):\n",
    "    if maxlen is None:\n",
    "        maxlen = max(len(s) for s in sequences)\n",
    "\n",
    "    out_secuences = []\n",
    "    for secuence in sequences:\n",
    "        if len(secuence) < maxlen: # Hago padding hasta max_len\n",
    "            if padding_pre:\n",
    "                sec_out = [value] * (maxlen - len(secuence)) + secuence\n",
    "            else:\n",
    "                sec_out = secuence + [value] * (maxlen - len(secuence))\n",
    "        else: # O me quedo con los max_len caracteres\n",
    "            if truncating_pre:\n",
    "                sec_out = secuence[-maxlen:]\n",
    "            else:\n",
    "                sec_out = secuence[:maxlen]\n",
    "        out_secuences.append(sec_out)\n",
    "\n",
    "    return np.array(out_secuences, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "q0Ob4hAWJkcv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows del dataset: 6000\n",
      "encoder_input_sequences shape: (6000, 16)\n",
      "decoder_input_sequences shape: (6000, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding_pre=False)\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK4blEEsRQv3"
   },
   "source": [
    "La última capa del modelo (softmax) necesita que los valores de salida\n",
    "del decoder (decoder_sequences) estén en formato oneHotEncoder.\\\n",
    "Se utiliza \"decoder_output_sequences\" con la misma estrategia con que se transformó la entrada del decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(x, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "3toZyIVEOC18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 18, 5722)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding_pre=False)\n",
    "decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
    "decoder_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJIsLBbj6rg"
   },
   "source": [
    "### 3 - Preparar los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los embeddings gloveembedding.pkl ya están descargados\n"
     ]
    }
   ],
   "source": [
    "url = 'https://drive.usercontent.google.com/download?id=1KY6avD5I1eI2dxQzMkR3WExwKwRq2g94&export=download&confirm=t&uuid=07c897f9-d9a1-4bdd-8cce-70c9dca2368a&at=AKSUxGMQs76z20Q73h7ULNM9qfje%3A1759553933720'\n",
    "output = 'gloveembedding.pkl'\n",
    "if os.access(os.path.join(base_dir, output), os.F_OK) is False:\n",
    "    download_dataset(url, base_dir, tmp_file=output, unzip=False)\n",
    "else:\n",
    "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ZgqtV8GpkSc8"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "class WordsEmbeddings(object):\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        # load the embeddings\n",
    "        words_embedding_pkl = Path(self.PKL_PATH)\n",
    "        if not words_embedding_pkl.is_file():\n",
    "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
    "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
    "            embeddings = self.convert_model_to_pickle()\n",
    "        else:\n",
    "            embeddings = self.load_model_from_pickle()\n",
    "        self.embeddings = embeddings\n",
    "        # build the vocabulary hashmap\n",
    "        index = np.arange(self.embeddings.shape[0])\n",
    "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
    "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
    "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
    "\n",
    "    def get_words_embeddings(self, words):\n",
    "        words_idxs = self.words2idxs(words)\n",
    "        return self.embeddings[words_idxs]['embedding']\n",
    "\n",
    "    def words2idxs(self, words):\n",
    "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
    "\n",
    "    def idxs2words(self, idxs):\n",
    "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
    "\n",
    "    def load_model_from_pickle(self):\n",
    "        self.logger.debug(\n",
    "            'loading words embeddings from pickle {}'.format(\n",
    "                self.PKL_PATH\n",
    "            )\n",
    "        )\n",
    "        max_bytes = 2**28 - 1 # 256MB\n",
    "        bytes_in = bytearray(0)\n",
    "        input_size = os.path.getsize(self.PKL_PATH)\n",
    "        with open(self.PKL_PATH, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "        embeddings = pickle.loads(bytes_in)\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "    def convert_model_to_pickle(self):\n",
    "        # create a numpy strctured array:\n",
    "        # word     embedding\n",
    "        # U50      np.float32[]\n",
    "        # word_1   a, b, c\n",
    "        # word_2   d, e, f\n",
    "        # ...\n",
    "        # word_n   g, h, i\n",
    "        self.logger.debug(\n",
    "            'converting and loading words embeddings from text file {}'.format(\n",
    "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
    "            )\n",
    "        )\n",
    "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
    "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
    "        structure = np.dtype(structure)\n",
    "        # load numpy array from disk using a generator\n",
    "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
    "            embeddings_gen = (\n",
    "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
    "                if len(line.split()[1:]) == self.N_FEATURES\n",
    "            )\n",
    "            embeddings = np.fromiter(embeddings_gen, structure)\n",
    "        # add a null embedding\n",
    "        null_embedding = np.array(\n",
    "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
    "            dtype=structure\n",
    "        )\n",
    "        embeddings = np.concatenate([embeddings, null_embedding])\n",
    "        # dump numpy array to disk using pickle\n",
    "        max_bytes = 2**28 - 1 # # 256MB\n",
    "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.PKL_PATH, 'wb') as f_out:\n",
    "            for idx in range(0, len(bytes_out), max_bytes):\n",
    "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class GloveEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
    "    PKL_PATH = 'gloveembedding.pkl'\n",
    "    N_FEATURES = 50\n",
    "    WORD_MAX_SIZE = 60\n",
    "\n",
    "class FasttextEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
    "    PKL_PATH = 'fasttext.pkl'\n",
    "    N_FEATURES = 300\n",
    "    WORD_MAX_SIZE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Mosj2-x-kXBK"
   },
   "outputs": [],
   "source": [
    "# Por una cuestion de RAM se utilizarán los embeddings de Glove de dimension 50\n",
    "model_embeddings = GloveEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "b9FS8ca1ke_B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing embedding matrix...\n",
      "number of null word embeddings: 30\n"
     ]
    }
   ],
   "source": [
    "# Crear la Embedding matrix de las secuencias\n",
    "# en inglés\n",
    "\n",
    "print('preparing embedding matrix...')\n",
    "embed_dim = model_embeddings.N_FEATURES\n",
    "words_not_found = []\n",
    "\n",
    "# word_index proviene del tokenizer\n",
    "\n",
    "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs))+1 # vocab_size\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        \n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        words_not_found.append(word)\n",
    "\n",
    "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix**2, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "FpzJODHBlAtE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3852, 50)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensión de los embeddings de la secuencia en inglés\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM"
   },
   "source": [
    "### 4 - Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "3fm3HCLMPSG-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translator(\n",
      "  (encoder_embedding_layer): Embedding(3852, 50)\n",
      "  (encoder): LSTM(50, 128, batch_first=True)\n",
      "  (decoder_embedding_layer): Embedding(5722, 128)\n",
      "  (decoder_lstm): LSTM(128, 128, batch_first=True)\n",
      "  (decoder_dense): Linear(in_features=128, out_features=5722, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Embedding, Module, LSTM, Linear\n",
    "\n",
    "class Translator(Module):\n",
    "    def __init__(self, num_words_input, embed_dim, embedding_matrix, num_words_output) -> None:\n",
    "        super().__init__()\n",
    "        n_units = 128\n",
    "\n",
    "        # training encoder\n",
    "        self.encoder_embedding_layer = Embedding(\n",
    "                num_embeddings=num_words_input,  # definido en el Tokenizador\n",
    "                embedding_dim=embed_dim,  # dimensión de los embeddings utilizados\n",
    "                #   input_length=max_input_len, # tamaño máximo de la secuencia de entrada\n",
    "                _weight=torch.nn.Parameter(torch.from_numpy(embedding_matrix.astype(np.float32))))  # matrix de embeddings\n",
    "        self.encoder_embedding_layer.weight.requires_grad = False # marcar como layer no entrenable\n",
    "        self.encoder = LSTM(input_size=embed_dim, hidden_size=n_units, batch_first=True)\n",
    "\n",
    "        # training decoder\n",
    "        self.decoder_embedding_layer = Embedding(num_embeddings=num_words_output, embedding_dim=n_units) #, input_length=max_out_len\n",
    "        self.decoder_lstm = LSTM(input_size=n_units, hidden_size=n_units, batch_first=True)\n",
    "\n",
    "        # Dense\n",
    "        self.decoder_dense = Linear(in_features=n_units, out_features=num_words_output)\n",
    "                \n",
    "    def forward(self, encoder_inputs, decoder_inputs):\n",
    "        encoder_inputs_x = self.encoder_embedding_layer(encoder_inputs)\n",
    "        _, encoder_states = self.encoder(encoder_inputs_x)\n",
    "\n",
    "        decoder_inputs_x = self.decoder_embedding_layer(decoder_inputs)\n",
    "        decoder_outputs, _ = self.decoder_lstm(decoder_inputs_x, encoder_states)\n",
    "        decoder_outputs = self.decoder_dense(decoder_outputs)\n",
    "        return decoder_outputs\n",
    "\n",
    "        \n",
    "model=Translator(num_words_input=nb_words, embed_dim=embed_dim, embedding_matrix=embedding_matrix, num_words_output=num_words_output)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Translator                               [1, 18, 5722]             --\n",
       "├─Embedding: 1-1                         [1, 16, 50]               (192,600)\n",
       "├─LSTM: 1-2                              [1, 16, 128]              92,160\n",
       "├─Embedding: 1-3                         [1, 18, 128]              732,416\n",
       "├─LSTM: 1-4                              [1, 18, 128]              132,096\n",
       "├─Linear: 1-5                            [1, 18, 5722]             738,138\n",
       "==========================================================================================\n",
       "Total params: 1,887,410\n",
       "Trainable params: 1,694,810\n",
       "Non-trainable params: 192,600\n",
       "Total mult-adds (Units.MEGABYTES): 5.52\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.88\n",
       "Params size (MB): 7.55\n",
       "Estimated Total Size (MB): 8.43\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo as torchinfo\n",
    "torchinfo.summary(model, input_size=[(1, max_input_len), (1, max_out_len)], dtypes=[torch.int, torch.int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TranslatorDataset(Dataset):\n",
    "    def __init__(self, encoder_input_sequences, decoder_input_sequences, decoder_targets):\n",
    "        self.encoder_input_sequences = torch.tensor(encoder_input_sequences, dtype=torch.int)\n",
    "        self.decoder_input_sequences = torch.tensor(decoder_input_sequences, dtype=torch.int)\n",
    "        self.decoder_targets = torch.tensor(decoder_targets, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoder_input_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.encoder_input_sequences[idx],\n",
    "                self.decoder_input_sequences[idx],\n",
    "                self.decoder_targets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4800. Validation size: 1200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_dataset, val_dataset = train_test_split(\n",
    "    TranslatorDataset(encoder_input_sequences, decoder_input_sequences, decoder_targets), test_size=0.2, random_state=42)\n",
    "print(f\"Train size: {len(train_dataset)}. Validation size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Translator(num_words_input=nb_words, embed_dim=embed_dim, embedding_matrix=embedding_matrix, num_words_output=num_words_output)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Tasa de aprendizaje\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 1.8292619239886603\n",
      "  Val Loss: 0.4145087894399961\n",
      "Epoch 2/15, Loss: 1.4387086504151423\n",
      "  Val Loss: 0.4113206118941307\n",
      "Epoch 3/15, Loss: 1.2000642161294819\n",
      "  Val Loss: 0.4295482021321853\n",
      "Epoch 4/15, Loss: 1.0001885218322277\n",
      "  Val Loss: 0.45125775333245594\n",
      "Epoch 5/15, Loss: 0.8343781223644813\n",
      "  Val Loss: 0.46851331464449564\n",
      "Epoch 6/15, Loss: 0.7003751460065444\n",
      "  Val Loss: 0.48192031465967494\n",
      "Epoch 7/15, Loss: 0.5908925608322024\n",
      "  Val Loss: 0.49682176353037355\n",
      "Epoch 8/15, Loss: 0.5003578964285552\n",
      "  Val Loss: 0.5093520157833894\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[177]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m                 epoch_loss += loss.item()\n\u001b[32m     32\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m  Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss/\u001b[38;5;28mlen\u001b[39m(encoder_input_sequences)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepocs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[177]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_dataset, val_dataset, optimizer, criterion, device, epocs)\u001b[39m\n\u001b[32m     15\u001b[39m     epoch_loss += loss.item()\n\u001b[32m     17\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepocs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss/\u001b[38;5;28mlen\u001b[39m(encoder_input_sequences)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     22\u001b[39m epoch_loss = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\miniconda3\\envs\\B3_AP\\Lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\miniconda3\\envs\\B3_AP\\Lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\miniconda3\\envs\\B3_AP\\Lib\\site-packages\\torch\\optim\\adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\miniconda3\\envs\\B3_AP\\Lib\\site-packages\\torch\\optim\\optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\miniconda3\\envs\\B3_AP\\Lib\\site-packages\\torch\\optim\\adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\miniconda3\\envs\\B3_AP\\Lib\\site-packages\\torch\\optim\\adam.py:651\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;66;03m# Update steps\u001b[39;00m\n\u001b[32m    647\u001b[39m \u001b[38;5;66;03m# If steps are on CPU, foreach will fall back to the slow path, which is a for-loop calling t.add(1) over\u001b[39;00m\n\u001b[32m    648\u001b[39m \u001b[38;5;66;03m# and over. 1 will then be wrapped into a Tensor over and over again, which is slower than if we just\u001b[39;00m\n\u001b[32m    649\u001b[39m \u001b[38;5;66;03m# wrapped it once now. The alpha is required to assure we go to the right overload.\u001b[39;00m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.compiler.is_compiling() \u001b[38;5;129;01mand\u001b[39;00m device_state_steps[\u001b[32m0\u001b[39m].is_cpu:\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_add_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_state_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    655\u001b[39m     torch._foreach_add_(device_state_steps, \u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def train(model, train_dataset, val_dataset, optimizer, criterion, device, epocs=15):\n",
    "    # input_batch: Secuencia de entrada (ej. frase en inglés)\n",
    "    # target_batch: Secuencia de salida DESEADA (ej. frase en español, incluyendo <EOS>)\n",
    "    \n",
    "    for epoch in range(epocs):\n",
    "        epoch_loss = 0\n",
    "        for (input, output_input, output_target) in train_dataset:\n",
    "            optimizer.zero_grad()\n",
    "            input =input.to(device)\n",
    "            output_input = output_input.to(device)\n",
    "            output_target = output_target.to(device)\n",
    "\n",
    "            output_pred = model(input, output_input)\n",
    "            loss = criterion(output_pred, output_target)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epocs}, Loss: {epoch_loss/len(encoder_input_sequences)}')\n",
    "\n",
    "        epoch_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for (input, output_input, output_target) in val_dataset:\n",
    "                input =input.to(device)\n",
    "                output_input = output_input.to(device)\n",
    "                output_target = output_target.to(device)\n",
    "\n",
    "                output_pred = model(input, output_input)\n",
    "                loss = criterion(output_pred, output_target)\n",
    "                epoch_loss += loss.item()\n",
    "        print(f'  Val Loss: {epoch_loss/len(encoder_input_sequences)}')\n",
    "\n",
    "train(model, train_dataset, val_dataset, optimizer, criterion, device, epocs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_urD1qO2kOx"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "n_units = 128\n",
    "\n",
    "# define training encoder\n",
    "encoder_inputs = Input(shape=(max_input_len))\n",
    "\n",
    "#encoder_embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)\n",
    "\n",
    "encoder_embedding_layer = Embedding(\n",
    "          input_dim=nb_words,  # definido en el Tokenizador\n",
    "          output_dim=embed_dim,  # dimensión de los embeddings utilizados\n",
    "          input_length=max_input_len, # tamaño máximo de la secuencia de entrada\n",
    "          weights=[embedding_matrix],  # matrix de embeddings\n",
    "          trainable=False)      # marcar como layer no entrenable\n",
    "\n",
    "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "encoder = LSTM(n_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# define training decoder\n",
    "decoder_inputs = Input(shape=(max_out_len))\n",
    "decoder_embedding_layer = Embedding(input_dim=num_words_output, output_dim=n_units, input_length=max_out_len)\n",
    "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "\n",
    "# Dense\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ljAyiBbG10U"
   },
   "outputs": [],
   "source": [
    "# Modelo completo (encoder+decoder) para poder entrenar\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1Wc1pnhIKJ6"
   },
   "outputs": [],
   "source": [
    "# Modelo solo encoder\n",
    "\n",
    "# define inference encoder\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "plot_model(encoder_model, to_file='encoder_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_xanat4INez"
   },
   "outputs": [],
   "source": [
    "# Modelo solo decoder (para realizar inferencia)\n",
    "\n",
    "# define inference decoder\n",
    "decoder_state_input_h = Input(shape=(n_units,))\n",
    "decoder_state_input_c = Input(shape=(n_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# En cada predicción habrá una sola palabra de entrada al decoder,\n",
    "# que es la realimentación de la palabra anterior\n",
    "# por lo que hay que modificar el input shape de la layer de Embedding\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "plot_model(decoder_model, to_file='decoder_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnlIx1Vezjwc"
   },
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets,\n",
    "    epochs=15, \n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVz1uug_zu2J"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbwn0ekDy_s2"
   },
   "source": [
    "### 5 - Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnkl3mSpsU_7"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 1:\n",
    "A deal is a deal -> Encoder -> enc(h1,c1)\n",
    "\n",
    "enc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\n",
    "\n",
    "step 2:\n",
    "dec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\n",
    "\n",
    "step 3:\n",
    "dec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\n",
    "\n",
    "step 4:\n",
    "dec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\n",
    "\n",
    "step 5:\n",
    "dec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\n",
    "\n",
    "step 6:\n",
    "dec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71XeCtfYmOFx"
   },
   "outputs": [],
   "source": [
    "# Armar los conversores de índice a palabra:\n",
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlUyp9M6ua2V"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(input_seq):\n",
    "    # Se transforma la sequencia de entrada a los estados \"h\" y \"c\" de la LSTM\n",
    "    # para enviar la primera vez al decoder\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "    # Se obtiene el índice que finaliza la inferencia\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "    \n",
    "    output_sentence = []\n",
    "    for _ in range(max_out_len):\n",
    "        # Predicción del próximo elemento\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        # Si es \"end of sentece <eos>\" se acaba\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        # Transformar idx a palabra\n",
    "        word = ''        \n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Actualizar los estados dada la última predicción\n",
    "        states_value = [h, c]\n",
    "\n",
    "        # Actualizar secuencia de entrada con la salida (re-alimentación)\n",
    "        target_seq[0, 0] = idx\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhGVjLKcunxW"
   },
   "outputs": [],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "translation = translate_sentence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYZ1Q_Z_2G4m"
   },
   "outputs": [],
   "source": [
    "input_test = \"My mother say hi.\"\n",
    "print('Input:', input_test)\n",
    "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
    "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "print(\"Padding del vector:\", encoder_sequence_test)\n",
    "\n",
    "print('Input:', input_test)\n",
    "translation = translate_sentence(encoder_sequence_test)\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkOjSJweqdF8"
   },
   "source": [
    "### 6 - Conclusión\n",
    "A primera vista parece que el modelo tendría que funcionar muy bien por el accuracy alcanzado. La realidad es que las respuestas no tienen que ver demasiado con la pregunta/traducción pero la respuesta en si tiene bastante coherencia.\\\n",
    "Para poder mejorar el modelo haría falta poder consumir todo el dataset y todo el vocabulario, pero la cantidad de RAM no es suficiente.\\\n",
    "Este problema se resuelve con:\n",
    "- Utilizando un DataGenerator para no levantar todo el dataset junto en el entrenamiento.\n",
    "- Transfer learning evitando tener que entrenar todo el modelo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSy0kaSKuC4-"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "B3_AP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
